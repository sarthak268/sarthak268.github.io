---
layout:     page
title:
permalink:  /
---

<!-- <style>
  body {
    font-size: 4px; /* Set the base font size for the entire document */
  }

  h1 {
    font-size: 0.2rem; /* Adjust the font size for headings */
  }

  p {
    font-size: 0.4rem; /* Adjust the font size for paragraphs */
  }
</style> -->

<div class="row">
    <div class="col-sm-6 col-xs-12">
        <img src="/img/cover3.jpg">
    </div>
    <div class="col-sm-6 col-xs-12" style="margin-bottom: 0;">
        Master's in Robotics<br>
        Carnegie Mellon University<br>
        sarthakb@andrew.cmu.edu
    </div>
</div>
<hr>

<a name="/news"></a>

## News

- <span style="font-size: 85%;">[Dec 23] Serving as Reviewer for ICML'24.</span>
- <span style="font-size: 85%;">[Oct 23] Serving as Reviewer for ICLR'24.</span>
- <span style="font-size: 85%;">[Sept 23] Presenting two papers in [CVEU workshop](https://cveu.github.io/) at ICCV 2023 on action anticipation from videos and talking face generation.</span>
- <span style="font-size: 85%;">[Sept 23] Selected as a student volunteer for ICCV'23.</span>
- <span style="font-size: 85%;">[May 23] Selected among 200 young researchers to attend the [HLF'23](https://www.heidelberg-laureate-forum.org/forum/10th-hlf-2023.html).</span>
- <span style="font-size: 85%;">[May 23] Work on Visual Concept Learning accepted in [CoLLAs'23](https://lifelong-ml.cc/Conferences/2023/venue) as one of only 12 oral presentations.</span>
- <span style="font-size: 85%;">[Dec 22] Work on talking face generation won the Best Demo Paper award at ACM MM Asia'23.</span>
- <span style="font-size: 85%;">[Sept 22] Joined AART Lab, CMU -- working on concept learning using domain knowledge priors and intent inference for human-robot collaboration.</span> 
- <span style="font-size: 85%;">[Aug 22] Joined Master's in Robotics Program at the [Robotics Institute, CMU](https://www.ri.cmu.edu/).</span>
- <span style="font-size: 85%;">[Jan 22] Joined [Preimage](https://www.preimage.ai/) as a Deep Learning Research Engineer -- working on Sparse-view 3D Reconstruction.</span>
- <span style="font-size: 85%;">[Oct 20] Joined [CLVR Lab](https://www.clvrai.com/), USC as a Visiting Researcher -- working on continual skill learning and OOD adaptation in robotics.</span>
- <span style="font-size: 85%;">[Aug 20] Joined [DeCLaRe Lab](https://declare-lab.net/), SUTD as a Research Assistant -- working on vision-language applications.</span>
- <span style="font-size: 85%;">[Aug 20] Graduated from [IIIT-Delhi](https://www.iiitd.edu.in/) with Honors.</span>
- <span style="font-size: 85%;">[Aug 19] Received Dean's Award for Excellent Academic Performance for 4 consecutive semesters.</span>
- <span style="font-size: 85%;">[Aug 19] Received Dean's Award for Innovation, Research, and Development for Bachelor's thesis.</span>
- <span style="font-size: 85%;">[May 19] Joined SUTD Brain Lab as a Visiting Researcher -- working on disentangling video sequences using Gaussian process priors.</span>
- <span style="font-size: 85%;">[May 19] Received [Indian National Academy of Engineering (INAE) Fellowship](https://www.inae.in/#) by IISc.</span>
- <span style="font-size: 85%;">[Aug 18] Placed 6th out of 70 International Teams: [AUVSI SUAS](https://suas-competition.org/), Maryland, USA.</span>
- <span style="font-size: 85%;">[Aug 16] Received Chairman's Merit Scholarship (4 / 278).</span>
- <span style="font-size: 85%;">[May 15] Received KVPY Fellowship (awarded to top 0.3%).</span>
</span>

<div id="read-more-button">
    <a nohref>Read more</a>
</div>

<hr>

<a name="/bio"></a>

## Bio

<span style="font-size: 85%;">I am a graduate student at <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a>. 
I am working at <a href="https://www.ri.cmu.edu/robotics-groups/advanced-agent-robotics-technology-lab/">Advanced Agents - Robotics Technology Lab</a> advised by <a href="https://en.wikipedia.org/wiki/Katia_Sycara">Dr. Katia Sycara</a>. Currently, I am working on the following problems: (1) manipulation of novel objects using LLMs via affordance reasoning, (2) short-context action anticipation for human-robot collaboration in manipulation tasks, (3) learning of visual (objects and scenes) and abstract (affordances and attributes) concepts using domain knowledge priors.</span>

<span style="font-size: 85%;">Most recently, I worked as a Deep Learning Engineer at <a href="https://preimage.ai/">Preimage</a>, where I worked on problems involving 3D vision for drone-based photogrammetry.
Previously, I worked as a Visiting Researcher at <a href="https://www.clvrai.com/">Cognitive Learning and Vision for Robotics (CLVR) Lab</a>, <a href="https://www.usc.edu/">University of Southern California (USC), USA</a> under the guidance of <a href="https://viterbi-web.usc.edu/~limjj/">Dr. Joseph Lim</a>. I majorly focused on problems involving adaptation of policies to novel unseen environments and continual learning of skills.
During my short stint as a Research Assistant at the <a href="https://declare-lab.net/index">Deep Cognition and Language Research Lab</a>, <a href="https://www.sutd.edu.sg/">Singapore University of Technology and Design, Singapore</a> advised by <a href="https://sporia.info/index">Dr. Soujanya Poria</a>, I worked on zero-shot visual classification and vision & language applications.
I completed my B.Tech (with Honors) in ECE from <a href="https://www.iiitd.ac.in/">IIIT-Delhi</a>. In my Bachelor's Thesis under <a href="http://faculty.iiitd.ac.in/~anands/">Dr. Saket Anand</a> in collaboration with <a href="https://pavanturaga.com/">Dr. Pavan Turaga, Geometric Media Lab</a> (Arizona State University, USA) at the <a href="https://cai.iiitd.ac.in/">Infosys Center of Artificial Intelligence</a>. Here, I worked on unsupervised representation learning for disentangling multiple factors of variation in images. You can find my Bachelor's thesis <a href="https://www.researchgate.net/profile/Sarthak-Bhagat/publication/346983991_Geometry_of_Neural_Network_based_Disentangled_Latent_Space_Models/links/5fd74b4445851553a0b59699/Geometry-of-Neural-Network-based-Disentangled-Latent-Space-Models.pdf">here</a>.
Previously, I worked as an intern at the <a href="https://sutdbrain.wordpress.com/about/">SUTD Brain Lab</a> under <a href="https://www.linkedin.com/in/nengli-lim-48a22b14/?originalSubdomain=sg">Dr. Nengli Lim</a> on the disentanglement of video sequences using Gaussian processes. I have also worked at <a href="http://robotics.iiitd.edu.in/coral/?page_id=20">Collaborative Robotics Lab (CORAL)</a> and <a href="https://sites.google.com/view/m00nlab/home?authuser=0">Multi-robot Autonomy (MOON) Lab</a> under <a href="https://eecs.iiserb.ac.in/faculty_profile.php?id=OQ==&lname=c3VqaXQ=">Dr. P.B. Sujit</a> on target tracking using deep reinforcement learning.</span>

<span style="font-size: 85%;">I am mainly interested in representation learning for visual data, computer vision for robotics, and robot learning.
Reach out to me at: <a href="mailto:sarthakb@andrew.cmu.edu">sarthakb@andrew.cmu.edu</a>.</span>

<br>

**_If you are interested in research collaboration, please drop me an email._**

<br><br>

<!-- <div class="row" id="timeline-logos">
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="//"><img src="/img/logos/iiitd.png"></a>
        </div>
        <div class="logo-desc">
            IIIT Delhi<br>
            2016 - 2020
        </div>
    </div>
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="//"><img src="/img/logos/sutd.png"></a>
        </div>
        <div class="logo-desc">
            SUTD<br>
            Summer 2019, 2020
        </div>
    </div>
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a href="//"><img src="/img/logos/usc.png"></a>
        </div>
        <div class="logo-desc">
            University of Southern California<br>
            2020 - 2021
        </div>
    </div>
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a target="_blank" href="//"><img src="/img/logos/preimage.jpg"></a>
        </div>
        <div class="logo-desc">
            Preimage<br>
            2021
        </div>
    </div>
    <div class="col-xs-3">
        <div class="logo-wrap">
            <span class="helper"></span>
            <a target="_blank" href="//"><img src="/img/logos/cmu.jpg"></a>
        </div>
        <div class="logo-desc">
            Carnegie Mellon University<br>
            2022-
        </div>
    </div>
</div> -->


<script src="/js/jquery.min.js"></script>
<script type="text/javascript">
    $('ul:gt(0) li:gt(12)').hide();
    $('#read-more-button > a').click(function() {
        $('ul:gt(0) li:gt(12)').show();
        $('#read-more-button').hide();
    });
</script>

---
<!-- 
[1]: //mlp.cc.gatech.edu
[2]: ///www.cc.gatech.edu/~dbatra/
[3]: //www.cc.gatech.edu/~parikh/
[4]: //www.qbi.uq.edu.au/professor-geoffrey-goodhill
[5]: //researchers.uq.edu.au/researcher/2490
[6]: http://cns.qbi.uq.edu.au/
[7]: //developers.google.com/open-source/gsoc/
[8]: /posts/summer-of-code/
[9]: /posts/gsoc-reunion-2014/
[10]: //blog.sdslabs.co/2012/09/hacku
[11]: //blog.sdslabs.co/2014/02/code-fun-do
[12]: //www.facebook.com/SDSLabs/posts/527540147292475
[13]: /posts/deloitte-cctc-3/
[14]: /posts/google-india-community-summit/
[15]: //blog.sdslabs.co/2013/10/syntax-error-2013
[16]: //sdslabs.co/
[17]: //erdos.sdslabs.co/
[18]: //projecteuler.net/
[19]: //github.com/abhshkdz/neural-vqa
[20]: //github.com/abhshkdz/HackFlowy
[21]: //github.com/abhshkdz/graf
[22]: //github.com/abhshkdz
[23]: //twitter.com/abhshkdz
[24]: //instagram.com/abhshkdz
[25]: http://x.abhishekdas.com/
[26]: https://abhishekdas.com/vqa-hat/
[27]: http://arxiv.org/abs/1606.03556
[28]: https://www.newscientist.com/article/2095616-robot-eyes-and-humans-fix-on-different-things-to-decode-a-scene/
[29]: https://www.technologyreview.com/s/601819/ai-is-learning-to-see-the-world-but-not-the-way-humans-do/
[30]: http://www.theverge.com/2016/7/12/12158238/first-click-deep-learning-algorithmic-black-boxes
[31]: http://iitr.ac.in/
[32]: https://www.facebook.com/dhruv.batra.1253/posts/1783087161932290
[33]: https://drive.google.com/file/d/1nObeNzl-sTy8I5QN1Jv8wscebKLv-6RY/view?usp=sharing
[34]: http://aideadlin.es/
[35]: //github.com/abhshkdz/neural-vqa-attention
[36]: https://snapresearchfellowship.splashthat.com/
[37]: https://www.youtube.com/watch?v=R4hugGnNr7s
[38]: https://www.youtube.com/watch?v=I9OlorMh7wU
[39]: https://adoberesearch.ctlprojects.com/fellowship/previous-fellowship-award-winners/
[40]: https://embodiedqa.org/
[41]: https://youtu.be/KAlGWMJnWyc?t=26m56s
[42]: https://2018gputechconf.smarteventscloud.com/connect/sessionDetail.ww?SESSION_ID=152715
[43]: https://www.ic.gatech.edu/news/600684/three-ic-students-earn-snap-research-awards
[44]: https://www.ic.gatech.edu/news/601084/new-research-fellowships-offer-two-students-funding-access-adobes-creative-cloud
[45]: https://github.com/facebookresearch/House3D
[46]: https://gkioxari.github.io/
[47]: https://research.fb.com/people/parikh-devi/
[48]: https://research.fb.com/people/batra-dhruv/
[49]: https://lvatutorial.github.io/
[50]: http://acl2018.org/tutorials/#connecting-language-and-vis
[51]: http://visualqa.org/workshop.html
[52]: http://on-demand.gputechconf.com/gtc/2018/video/S8582/
[53]: https://visualdialog.org/challenge/2018
[54]: https://youtu.be/gz2VoDrvX-A?t=1h19m58s
[55]: https://research.fb.com/people/rabbat-mike/
[56]: https://www.cs.mcgill.ca/~jpineau/
[57]: https://visualdialog.org/challenge/2018#winners
[58]: https://www.youtube.com/watch?v=xoHvho-YRgs&t=7330
[fb-fellow-page]: https://research.fb.com/announcing-the-2019-facebook-fellows-and-emerging-scholars/
[joelle-corl18-talk-mention]: https://www.youtube.com/watch?v=FSsEqEJKo8A&t=3497
[visdial-challenge-2]: https://visualdialog.org/challenge/2019
[ic-gt-article]: https://www.ic.gatech.edu/news/617061/see-and-say-abhishek-das-working-provide-crucial-communication-tools-intelligent-agents
[caliper]: https://caliper.ai
[felix-hill]: https://fh295.github.io
[laura-rimell]: http://www.rimell.cc/laura/
[stephen-clark]: https://sites.google.com/site/stephenclark609/
[andrej-karpathy]: https://karpathy.ai/
[vigil19]: https://vigilworkshop.github.io/2019
[tarmac-icml-talk]: https://www.facebook.com/icml.imls/videos/444326646299556/
[mastodon]: https://mastodon.social/web/accounts/1011404
[conquerearth]: https://conquer.earth/abhshkdz
[qa-probing-icml20-talk]: https://slideslive.com/38928261/probing-emergent-semantics-in-predictive-agents-via-question-answering
[vigil20]: https://vigilworkshop.github.io
[ocp]: https://opencatalystproject.org
[ocp-cnbc]: https://www.cnbc.com/2020/10/14/facebook-to-use-ai-in-bid-to-improve-renewable-energy-storage.html
[ocp-engadget]: https://engadget.com/facebook-deploys-its-ai-to-find-green-energy-storage-solutions-130041147.html
[ocp-fortune]: https://fortune.com/2020/10/14/facebook-ai-open-catalyst-dataset-chemistry-renewable-energy/
[ocp-venturebeat]: https://venturebeat.com/2020/10/14/facebook-and-carnegie-mellon-launch-project-to-discover-better-ways-to-store-renewable-energy/
[aipaygrad.es]: https://aipaygrad.es
[sigma-xi-thesis-award]: https://cpb-us-w2.wpmucdn.com/sites.gatech.edu/dist/0/283/files/2021/03/2021-Sigma-Xi-Research-Award-Winners.final_.pdf
[coc-dissertation-award]: https://sites.gatech.edu/gtcomputingawards2021/graduate-student-awards/
[thesis-pdf]: https://drive.google.com/file/u/2/d/1b2Gonazl1Os0eLPV9frkucEqSuRroEvD/view?usp=sharing
[aaai-dissertation-award]: https://aaai.org/Awards/dissertation-award.php -->
